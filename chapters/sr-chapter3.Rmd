---
title: "Chapter 3 - Sampling from Posterior"
author: "P Winston Miller"
date: "2025-06-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rethinking)
library(patchwork)
```

```{r}
p_grid = seq(from = 0, to = 1, length.out = 1000)
likelihood = dbinom(x = 6, size = 9, prob = p_grid)
prior = rep(1,1000)
posterior = likelihood*prior
posterior = posterior/sum(posterior)
```
- generate posterior using our old water-land samples from chapter 2

Now to sample from posterior
```{r}
samples = sample( p_grid , prob=posterior , size=10000 , replace=TRUE )
```
- sample function randomly pulls samples from a vectior
- sampling from p_grid
- the probability of sampling each value from p_grid is given via the posterior
```{r}
head(p_grid);head(posterior)
```

```{r}
plot( samples )
```
- scatter plot of all the samples
- y-axis is the probility of each sample
- the x-axis is just the vector position of that probability

```{r}
dens(samples)
```
- this is a density plot of those samples from above
- this is similar to the ideal posterior calculated via the large-grid 
  approximation in chapter 2

What is the probability that p is < 0.05
```{r}
sum(posterior[ p_grid < 0.5 ])
```
- 17%

So, how to do this with samples?
```{r}
sum(samples<0.5)/10000 # 10,000 = total number of samples
```
- almost but not quite the same answer
- good enough for government work lol

Okay, what is the probability that water is between 0.5 and 0.8?
```{r}
sum(samples > 0.5 & samples < 0.75)/1e4
```

What is the highest density of probability?
- below is 50% probability
```{r}
HPDI(samples , prob=0.5 )
```
- this interval contains 50% of the probability density

```{r}
HPDI( samples , prob=0.95 )
```
- this interval contains 95% of the probability
- not super useful in this example tbh

```{r}
map_est = p_grid[which.max(posterior)]
map_est
```
- this is the point estimate with the highest posterior probability

```{r}
mode_est = chainmode(samples , adj=0.01)
mode_est
```
- this is the most common sample

```{r}
mean_est = mean(samples)
med_est = median(samples)
mean_est; med_est
```

```{r}
ggplot(data = data.frame(x = samples,
                         y = 1:length(samples)), aes(y = x)) + 
  geom_density() +
  geom_hline(yintercept = map_est, color = "red") + # MAP
  geom_hline(yintercept = mode_est, color = "blue") + # MODE
  geom_hline(yintercept = mean_est, color = "green") + # MEAN
  geom_hline(yintercept = med_est, color = "yellow") + # MEDIAN
  coord_flip()
```

```{r}
dbinom(x = 0:3, size = 2, prob = 0.7)
```
- this is binomial, so the prob is the probability of seeing 1 as opposed to 0
- dbinom calculates the probability of a value given the number of trials and the probability
- in 2 tosses, we see 
  - 0 = 9% -> no 1s 
  - 1 = 42% -> 1 1s
  - 2 = 49% -> 2 1s
  - 3 = 0% since there are only 2 trials, will never see 1s

```{r}
rbinom(n = 1, size = 2, prob = 0.7)
```
- rbinom calculates the number of observations of 1s in a set number of trials with certain probability
- so in this random example, saw 1 observation in 2 trials
- n is the number of times it runs the set, so it will simulate 2 trials + report number of observations 
  for as many n as input

```{r}
test_data = rbinom(n = 1e5, size = 2, prob = 0.7)
table(test_data)/1e5
```
- so lets run it for 10,000 different sets of trials
- so these percentages match up approximately with the calculated samples from dbinom
- THIS IS SAMPLING
- so, only 2 trials is not very much, lets do this again but simulate 9 trials

```{r}
test_data2 = rbinom(n = 1e5, size = 9, prob = 0.7) # simulating the glob tossing
hist(test_data2)
```
- this is simulating the glob tossing data set exactly
- this hist shows how many successes we had in 9 trials
 
```{r}
predictions = rbinom(1e5, size = 9, prob = samples)
mean(samples);median(samples)
simplehist(predictions)
```
- above, I generated 10,000 predictions of 9 trials from each probability I sampled
  from the posterior
- as I can, see the mean and median of samples are 0.63/0.64, which when multiplied
  by 9 trials is a little less than 6 tosses, which is reflected in the predicted
  values


  


